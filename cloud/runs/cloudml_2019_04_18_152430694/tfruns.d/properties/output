
> library(keras)

> library(tm)

> library(tensorflow)

> sess = tf$Session()

> hello <- tf$constant("Hello, TensorFlow!")

> sess$run(hello)
[1] "Hello, TensorFlow!"

> amazon <- read.csv("reviews.csv", stringsAsFactors = F)

> one.hot <- function(Z) {
+     return(unname(as.matrix(as.data.frame(t(model.matrix(~as.factor(Z) + 
+         0))))))
+ }

> testsamples <- sample(1:nrow(amazon), ((nrow(amazon))/2))

> trainsamples <- setdiff(1:nrow(amazon), testsamples)

> ytrain <- amazon[trainsamples, ]$Score

> ytest <- amazon[testsamples, ]$Score

> length(testsamples) == length(trainsamples)
[1] TRUE

> samples <- amazon[, 10]

> rm(amazon)

> samples <- removeWords(samples, stopwords("en"))

> samples <- stripWhitespace(samples)

> max_features <- 1000

> gc()
           used  (Mb) gc trigger  (Mb) max used  (Mb)
Ncells  1601796  85.6    4703850 251.3  3114037 166.4
Vcells 19104592 145.8   50232698 383.3 50232693 383.3

> tokenizer <- text_tokenizer(num_words = max_features) %>% 
+     fit_text_tokenizer(samples)

> oh_results <- texts_to_matrix(tokenizer, samples, 
+     mode = "tfidf")

> dim(oh_results)
[1] 568454   1000

> x_train <- oh_results[trainsamples, ]

> x_test <- oh_results[testsamples, ]

> rm(oh_results)

> ytrain <- t(one.hot(ytrain))

> ytest <- t(one.hot(ytest))

> batch_size <- 32

> embedding_dims <- 50

> filters <- 250

> kernel_size <- 3

> hidden_dims <- 250

> epochs <- 10

> fitlist <- list()

> maxlen <- dim(x_train)[2]

> L1 = 0

> L2 = 0

> DO = 0.2

> OP = "adadelta"

> Node = 400

> model <- keras_model_sequential() %>% layer_dense(Node, 
+     activation = "relu", input_shape = maxlen, kernel_regularizer = regularizer_l1_l2(l1  .... [TRUNCATED] 

> model %>% compile(loss = "categorical_crossentropy", 
+     optimizer = OP, metrics = "accuracy")

> FIT <- model %>% fit(x_train, (ytrain), batch_size = batch_size, 
+     epochs = epochs, validation_data = list(x_test, (ytest)))

> save_model_hdf5(model, paste0(OP, ".h5"))

> fitlist[[1]] <- FIT

> fitlist[[1]]$OPT <- OP

> L1 = 0

> L2 = 0

> DO = 0.2

> OP = "nadam"

> Node = 400

> model <- keras_model_sequential() %>% layer_dense(Node, 
+     activation = "relu", input_shape = maxlen, kernel_regularizer = regularizer_l1_l2(l1  .... [TRUNCATED] 

> model %>% compile(loss = "categorical_crossentropy", 
+     optimizer = OP, metrics = "accuracy")

> FIT <- model %>% fit(x_train, (ytrain), batch_size = batch_size, 
+     epochs = epochs, validation_data = list(x_test, (ytest)))

> save_model_hdf5(model, paste0(OP, ".h5"))

> fitlist[[2]] <- FIT

> fitlist[[2]]$OPT <- OP

> L1 = 0

> L2 = 0

> DO = 0.2

> OP = "adamax"

> Node = 400

> model <- keras_model_sequential() %>% layer_dense(Node, 
+     activation = "relu", input_shape = maxlen, kernel_regularizer = regularizer_l1_l2(l1  .... [TRUNCATED] 

> model %>% compile(loss = "categorical_crossentropy", 
+     optimizer = OP, metrics = "accuracy")

> FIT <- model %>% fit(x_train, (ytrain), batch_size = batch_size, 
+     epochs = epochs, validation_data = list(x_test, (ytest)))

> save_model_hdf5(model, paste0(OP, ".h5"))

> fitlist[[3]] <- FIT

> fitlist[[3]]$OPT <- OP

> save(fitlist, file = "fitlist.RData")
