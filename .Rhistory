library(RColorBrewer)
library(rgeos)
library(rgdal)
library(maptools)
library(scales)
library(dplyr)
library(ggmap)
library(dplyr)
library(Cairo)
library(RColorBrewer)
library(htmltools)
install.packages("htmltools")
library(htmltools)
install.packages("tinytex")
1+1+1
require("VGAM")
require(VGAM)
heaven.fit = vglm(cbind(y1,y2,y3)~gender+race, family=multinomial, data=mat)
require(VGAM)
mat<-matrix(NA,4,5)
mat[1,]<-c(1,1,88,16,2)
mat[2,]<-c(1, 0, 54, 7 ,5)
mat[3,]<-c(0 ,1, 397 ,141 ,24)
mat[4,]<-c(0 ,0 ,235, 189, 39)
mat
mat<-as.data.frame(mat)
names(mat)<-c("race","gender","y1","y2","y3")
heaven.fit = vglm(cbind(y1,y2,y3)~gender+race, family=multinomial, data=mat)
(heaven.fit )
summary(heaven.fit )
(heaven.fit )
mat
(heaven.fit )
require(VGAM)
mat<-matrix(NA,4,5)
mat[1,]<-c(1,1,88,16,2)
mat[2,]<-c(1, 0, 54, 7 ,5)
mat[3,]<-c(0 ,1, 397 ,141 ,24)
mat[4,]<-c(0 ,0 ,235, 189, 39)
mat
mat<-as.data.frame(mat)
names(mat)<-c("race","gender","y1","y2","y3")
heaven.fit = vglm(cbind(y1,y2,y3)~gender+race, family=multinomial, data=mat)
summary(heaven.fit )
(heaven.fit )
sum(coef(heaven.fit )[1:2])	#intercept
sum(coef(heaven.fit )[3:4]) 	#x_i1
sum(coef(heaven.fit )[5:6])	#x_i2
heaven.fitt = vglm(cbind(y1,y2,y3)~gender, family=multinomial, data=mat)
heaven.fitt
(heaven.fit )
heaven.fitt = vglm(cbind(y1,y2,y3)~race, family=multinomial, data=mat)
heaven.fitt
summary(heaven.fit )
1-pchisq( 46.80651 -  6.0748, 4-2)
options(scipen = 999)
1-pchisq( 46.80651 -  6.0748, 4-2)
1-pchisq( 46.80651 -  6.0748, 4-2)
nat<-matrix(NA,4,5)
nat[1,]<-c(1,1,64 ,9 ,15)
nat[2,]<-c(1, 0, 25 ,5 ,13)
nat[3,]<-c(0 ,1, 371, 49 ,74)
nat[4,]<-c(0 ,0 ,250 ,45, 71)
nat
nat<-as.data.frame(nat)
names(nat)<-c("race","gender","y1","y2","y3")
xamp = vglm(cbind(y1,y2,y3)~race, family=multinomial, data=mat)
xamp = vglm(cbind(y1,y2,y3)~race+gender, family=multinomial, data=mat)
xamp1 = vglm(cbind(y1,y2,y3)~race, family=multinomial, data=mat)
xamp1
xamp
xamp
xamp = vglm(cbind(y1,y2,y3)~race+gender, family=multinomial, data=nat)
xamp1 = vglm(cbind(y1,y2,y3)~race, family=multinomial, data=nat)
xamp
xamp = vglm(cbind(y1,y2,y3)~race+gender, family=multinomial, data=nat)
xamp1 = vglm(cbind(y1,y2,y3)~race, family=multinomial, data=nat)
xamp1
xamp
xamp1 = vglm(cbind(y1,y2,y3)~gender, family=multinomial, data=nat)
xamp1
xamp1 = vglm(cbind(y1,y2,y3)~race, family=multinomial, data=nat)
xamp1
knitr::opts_chunk$set(echo = TRUE)
source('./hw3_514.R')
set.seed(1234)
require(MASS)
m1=50;mu1=1;s1=.5
m2=50;mu2=2;s2=.7
c(xin,y) %<-% generate.1d.dataset(m1,mu1,s1,m2,mu2,s2)
plot(xin,col=y+3)
bayes.cut2=function(mu1,s1,mu2,s2){
ff=function(x){dnorm(x,mu2,s2) - dnorm(x,mu1,s1)}
uniroot(ff,c(mu1,mu2))$root
}
cut=bayes.cut2(mu1,s1,mu2,s2)
abline(h=cut)
h1=hist(xin[y==0], col=rgb(0,1,0,1/4), xlim=c(0,4),ylim=c(0,30))
h2=hist(xin[y==1], col=rgb(0,0,1,1/4), xlim=c(0,4),ylim=c(0,30), add=T)
abline(v=cut)
error=.5*pnorm(cut,mu2,s2)+.5*(1-pnorm(cut,mu1,s1))
error
dat <- generate.2d.dataset(m1,mu1,s1,m2,mu2,s2)
glm(dat$y ~ dat$x , family = binomial)
cost
knitr::opts_chunk$set(echo = TRUE)
source('./hw3_514.R')
set.seed(1234)
require(MASS)
m1=50;mu1=1;s1=.5
m2=50;mu2=2;s2=.7
c(xin,y) %<-% generate.1d.dataset(m1,mu1,s1,m2,mu2,s2)
DF <- list(x=xin,y=y); head(DF$x)
plot(xin,col=y+3)
bayes.cut2=function(mu1,s1,mu2,s2){
ff=function(x){dnorm(x,mu2,s2) - dnorm(x,mu1,s1)}
uniroot(ff,c(mu1,mu2))$root
}
cut=bayes.cut2(mu1,s1,mu2,s2)
abline(h=cut)
h1=hist(xin[y==0], col=rgb(0,1,0,1/4), xlim=c(0,4),ylim=c(0,30))
h2=hist(xin[y==1], col=rgb(0,0,1,1/4), xlim=c(0,4),ylim=c(0,30), add=T)
abline(v=cut)
error=.5*pnorm(cut,mu2,s2)+.5*(1-pnorm(cut,mu1,s1))
error
f.prop <- function(X, b, w ){	 sigmoid( b + X %*% w )  }
NLL <- function(x,y,b,w ){
yhat=f.prop(x,b,w )
m = length(yhat)
(-1/m)*(sum(log(yhat[y==1]))+sum(log(1-yhat[y==0])))}
SE <- function(x,y,b,w ){
yhat=f.prop(x,b,w )
m = length(yhat)
e = matrix(y - yhat,ncol=1)
(1/(2*m) )*sum(e^2)
}
knitr::opts_chunk$set(echo = TRUE)
source('./hw3_514.R')
set.seed(1234)
require(MASS)
m1=50;mu1=1;s1=.5
m2=50;mu2=2;s2=.7
c(xin,y) %<-% generate.1d.dataset(m1,mu1,s1,m2,mu2,s2)
DF <- list(x=xin,y=y); head(DF$x)
plot(xin,col=y+3)
bayes.cut2=function(mu1,s1,mu2,s2){
ff=function(x){dnorm(x,mu2,s2) - dnorm(x,mu1,s1)}
uniroot(ff,c(mu1,mu2))$root
}
cut=bayes.cut2(mu1,s1,mu2,s2)
abline(h=cut)
h1=hist(xin[y==0], col=rgb(0,1,0,1/4), xlim=c(0,4),ylim=c(0,30))
h2=hist(xin[y==1], col=rgb(0,0,1,1/4), xlim=c(0,4),ylim=c(0,30), add=T)
abline(v=cut)
error=.5*pnorm(cut,mu2,s2)+.5*(1-pnorm(cut,mu1,s1))
error
f.prop <- function(X, b, w ){	 sigmoid( b + X %*% w )  }
NLL <- function(x,y,b,w ){
yhat=f.prop(x,b,w )
m = length(yhat)
(-1/m)*(sum(log(yhat[y==1]))+sum(log(1-yhat[y==0])))}
SE <- function(x,y,b,w ){
yhat=f.prop(x,b,w )
m = length(yhat)
e = matrix(y - yhat,ncol=1)
(1/(2*m) )*sum(e^2)
}
b.prop <- function(x,y,yhat, neg.logll=T){
if( neg.logll == T) {
db <- ( 1/length(y) ) * sum(yhat-y)
dw <- (1/length(y) ) * colSums( t(yhat-y) %*% x ) }
else {
db <- ( 1/length(y) ) * sum((yhat - y) * yhat * (matrix(1,length(y),1)-yhat))
dw <- (1/length(y) ) * (t((yhat - y) * yhat * (matrix(1,length(y),1)-yhat)) %*% x) }
return( list(db = db, dw = dw ) )}
knitr::opts_chunk$set(echo = TRUE)
source('./hw3_514.R')
set.seed(1234)
require(MASS)
m1=50;mu1=1;s1=.5
m2=50;mu2=2;s2=.7
c(xin,y) %<-% generate.1d.dataset(m1,mu1,s1,m2,mu2,s2)
DF <- list(x=xin,y=y); head(DF$x)
plot(xin,col=y+3)
bayes.cut2=function(mu1,s1,mu2,s2){
ff=function(x){dnorm(x,mu2,s2) - dnorm(x,mu1,s1)}
uniroot(ff,c(mu1,mu2))$root
}
cut=bayes.cut2(mu1,s1,mu2,s2)
abline(h=cut)
h1=hist(xin[y==0], col=rgb(0,1,0,1/4), xlim=c(0,4),ylim=c(0,30))
h2=hist(xin[y==1], col=rgb(0,0,1,1/4), xlim=c(0,4),ylim=c(0,30), add=T)
abline(v=cut)
error=.5*pnorm(cut,mu2,s2)+.5*(1-pnorm(cut,mu1,s1))
error
f.prop <- function(X, b, w ){	 sigmoid( b + X %*% w )  }
NLL <- function(x,y,b,w ){
yhat=f.prop(x,b,w )
m = length(yhat)
(-1/m)*(sum(log(yhat[y==1]))+sum(log(1-yhat[y==0])))}
SE <- function(x,y,b,w ){
yhat=f.prop(x,b,w )
m = length(yhat)
e = matrix(y - yhat,ncol=1)
(1/(2*m) )*sum(e^2)
}
b.prop <- function(x,y,yhat, neg.logll=T){
if( neg.logll == T) {
db <- ( 1/length(y) ) * sum(yhat-y)
dw <- (1/length(y) ) * colSums( t(yhat-y) %*% x ) }
else {
db <- ( 1/length(y) ) * sum((yhat - y) * yhat * (matrix(1,length(y),1)-yhat))
dw <- (1/length(y) ) * (t((yhat - y) * yhat * (matrix(1,length(y),1)-yhat)) %*% x) }
return( list(db = db, dw = dw ) )}
num.gradient <- function(cost,x,y,b,w,h=1e-8, neg.logll=T )  {
db <- ( cost(x, y , b + h , w , neg.logll  = neg.logll   ) -
cost(x, y , b - h , w   , neg.logll = neg.logll   ) ) / (2*h)
dw<-w
for( i in 1:length(w) ) {
wP <- wM <-w; wP[i] <- wP[i]+h; wM[i] <- wM[i]-h
dw[i] <- (cost(x, y , b , wP , neg.logll =  neg.logll ) -
cost(x, y, b, wM  , neg.logll =   neg.logll ) ) / (2*h)  }
return( list(db = db, dw = dw ) )}
install.packages("downloader")
getwd()
setwd("G:\\math\\514")
source('hw4_514.R')
source('hw4_514.R')
library(MASS)
library(zeallot)
download_mnist()
load_image_file("train-images-idx3-ubyte")
load_image_file("train-images-idx3-ubyte.gz")
load_image_file
load_image_file("train-images-idx3-ubyte.gz")
library(knitr)
purl("hw4_514.Rmd")
