degree=15
lm.fit = lm(y ~ poly(x,degree,raw=FALSE), data=data.frame(y=y.set,x=x.set))
y = predict.lm(lm.fit,data.frame(x=xgrid))
#plot(xgrid,y,type="l",col="black",lwd=2)
#legend("topright", legend = c(num_hidden,paste("degree=",degree)), col = colors,lwd=2 )
nnet1.fit( x, y, 1 , 2 , 150000, 1, Activation = tanh, Output = Identity )
y
c(x,y,xgrid,ygrid) %<-% data.lawrence.giles(12345)
y
nnet1.fit
unlink('G:/math/514/hw5_514_cache', recursive = TRUE)
P <- .995
options(width = 1000)
setwd("G:/bs/")
bsno <- 35783
source("BSv3.R")
blerg <- do.call(rbind, stratum );nrow(blerg)
datz <- rbind(datP , datN); nrow(datz)
all( (datz$ID %in% blerg$ID) == T)
all( (blerg$ID %in% datz$ID) == T)
sum( datz$CSR_PRVDD  ) ==sum( blerg$CSR_PRVDD )
options(scipen=999)
DFa <- data.frame( sapply(stratum,function(X) min(X$CSR_PRVDD))  ,
sapply(stratum,function(X) max(X$CSR_PRVDD))   )
DFa[,2] <- apply(DFa,1,function(X)    paste0( "(" ,round(X[1],2),", ",round(X[2],2),")" ) )
DFa[,1] <-   sapply(stratum,function(X) max(X$Stratum) )
colnames(DFa) <- c("Stratum" , "Bounds")
DFa$Variant <- sapply(stratum, function(X) X$Variant[1] )
DFa$payment <- sapply(stratum, function(X) X$payment[1] )
DFa$TotAmnt <- sapply(stratum, function(X) X$AMOUNT[1] )
DFa$N_h <- sapply(stratum,nrow)
DFa$MINn <- 0;
for( i in 1:length(censam)){ 	if(censam[i] == "C"){
DFa$MINn[i] <- DFa$N_h[i]}else{DFa$MINn[i] <- 30} }
DFa$ss_err <- round( sapply(stratum , function(X) var(X$error )   ), 2 )
DFa$s_err <- round( sqrt( DFa$ss_err  ) ,2  )
DFa[is.na(DFa)] <- 0
Nh <- DFa$N_h
N <- sum( DFa$N_h )
print(DFa, row.names = F)
DF <- DFa[ which(DFa$N_h != DFa$MINn) , ]
DF$mean_err <- round( sapply(stratum[DF$Stratum], function(X) mean(X$error )   ), 4 )
DF$s_err <- round( sapply(stratum[DF$Stratum], function(X) sd(X$error )   ), 4 )
N <- DF$N_h
print(DF[,-c((ncol(DF)-1),ncol(DF))], row.names = F)
print( head(stratum[[2]])[,-c(4,(ncol(DF)-1),ncol(DF))], row.names = F)
numerator <- DF$N_h * DF$s_err
EO<-list()
for (i in 1:nrow(DF)){ EO[[i]]<- sqrt(seq(30,(N[i]-1),1)* (seq(30,(N[i ]-1),1)+1))}
for (i in 1:nrow(DF)){	EO[[i]]<-	numerator[i]/EO[[i]]} # NS/sqrt(n*n+1)
for (i in 1:length(numerator)) { EO[[i]]<-data.frame(EO[[i]],rep( DF$Stratum[i],length(
EO[[i]]))) }		#this convert into DF and put statum ID
EO<-do.call(rbind.data.frame, EO)
colnames(EO)<-c("PV","Stratum");
EO<-EO[order(-EO$PV),]
head(EO)
matx<-matrix(NA,nrow(EO),2)
matx[,1]<-EO$PV; matx[,2]<-EO$Stratum;
matx<- cbind(matx,matrix(0,nrow(EO),nrow(DFa) ),0,0)
colnames(matx) <- c("PV","Stratum", paste0("h_",DFa$Stratum), "n" , "Sd" )
######
matx <- rbind( matx[1,]*0, matx )
N <- DFa$N_h #nrow(matx)
matx[ 1 ,3:(ncol(matx) - 2)  ] <- DFa$MINn
matx[ 1 ,(ncol(matx) - 1) ] <- sum(matx[ 1 ,3:(ncol(matx) - 2)  ])
matx[ 1 ,(ncol(matx)) ] <- sqrt( sum((N*(N-matx[1,3:(ncol(matx)-2)])*
DFa$ss_err)/  (matx[1,3:(ncol(matx)-2)]) ) )
for (i in 2:10){
matx[i, 3:(2+nrow(DFa)) ] <- matx[i-1, 3:(2+nrow(DFa)) ]
matx[ i , which( colnames(matx) == paste0("h_", matx[i, 2] ) )] <-
matx[ i , which( colnames(matx) == paste0("h_", matx[i, 2] ) )] + 1
matx[i, (ncol(matx)-1)] <- sum(matx[i, 3:(ncol(matx)-2)] )
}
head(matx)
i = 2
matx[i-1, 3:(2+nrow(DFa)) ]
matx
head(matx)
matx<-matrix(NA,nrow(EO),2)
matx[,1]<-EO$PV; matx[,2]<-EO$Stratum;
matx<- cbind(matx,matrix(0,nrow(EO),nrow(DFa) ),0,0)
colnames(matx) <- c("PV","Stratum", paste0("h_",DFa$Stratum), "n" , "Sd" )
matx <- rbind( matx[1,]*0, matx )
N <- DFa$N_h #nrow(matx)
matx[ 1 ,3:(ncol(matx) - 2)  ] <- DFa$MINn
matx[ 1 ,(ncol(matx) - 1) ] <- sum(matx[ 1 ,3:(ncol(matx) - 2)  ])
matx[ 1 ,(ncol(matx)) ] <- sqrt( sum((N*(N-matx[1,3:(ncol(matx)-2)])*
DFa$ss_err)/  (matx[1,3:(ncol(matx)-2)]) ) )
round(matx[ 1, ]  ,2)
as.data.frame( round(matx[ 1, ]  ,2) )
as.data.frame( round(t(matx[ 1, ]  ,2) ))
as.data.frame( round(matx[ 1, ]  ,2) )
t( as.data.frame( round(matx[ 1, ]  ,2) ) )
datmat <- t( as.data.frame( round(matx[ 1, ]  ,2) ) )
rownames(datmat) <- NULL
print( datmat, row.names = F )
beep("mario")
require(beepr)
beep("mario")
print( head(round(matx,2)) , row.names = F )
print( as.data.frame( head(round(matx,2)) ) , row.names = F )
unlink('G:/bs/HIOS-11512_cache', recursive = TRUE)
unlink('G:/bs/HIOS-11512_cache', recursive = TRUE)
P <- .995
options(width = 1000)
setwd("G:/bs/")
bsno <- 11512
source("BSv3.R")
require(beepr)
blerg <- do.call(rbind, stratum );nrow(blerg)
datz <- rbind(datP , datN); nrow(datz)
all( (datz$ID %in% blerg$ID) == T)
all( (blerg$ID %in% datz$ID) == T)
sum( datz$CSR_PRVDD  ) ==sum( blerg$CSR_PRVDD )
#beep("mario")
options(scipen=999)
DFa <- data.frame( sapply(stratum,function(X) min(X$CSR_PRVDD))  ,
sapply(stratum,function(X) max(X$CSR_PRVDD))   )
DFa[,2] <- apply(DFa,1,function(X)    paste0( "(" ,round(X[1],2),", ",round(X[2],2),")" ) )
DFa[,1] <-   sapply(stratum,function(X) max(X$Stratum) )
colnames(DFa) <- c("Stratum" , "Bounds")
DFa$Variant <- sapply(stratum, function(X) X$Variant[1] )
DFa$payment <- sapply(stratum, function(X) X$payment[1] )
DFa$TotAmnt <- sapply(stratum, function(X) X$AMOUNT[1] )
DFa$N_h <- sapply(stratum,nrow)
DFa$MINn <- 0;
for( i in 1:length(censam)){ 	if(censam[i] == "C"){
DFa$MINn[i] <- DFa$N_h[i]}else{DFa$MINn[i] <- 30} }
DFa$ss_err <- round( sapply(stratum , function(X) var(X$error )   ), 2 )
DFa$s_err <- round( sqrt( DFa$ss_err  ) ,2  )
DFa[is.na(DFa)] <- 0
Nh <- DFa$N_h
N <- sum( DFa$N_h )
print(DFa, row.names = F)
DF <- DFa[ which(DFa$N_h != DFa$MINn) , ]
DF$mean_err <- round( sapply(stratum[DF$Stratum], function(X) mean(X$error )   ), 4 )
DF$s_err <- round( sapply(stratum[DF$Stratum], function(X) sd(X$error )   ), 4 )
N <- DF$N_h
print(DF[,-c((ncol(DF)-1),ncol(DF))], row.names = F)
numerator <- DF$N_h * DF$s_err
EO<-list()
for (i in 1:nrow(DF)){ EO[[i]]<- sqrt(seq(30,(N[i]-1),1)* (seq(30,(N[i ]-1),1)+1))}
for (i in 1:nrow(DF)){	EO[[i]]<-	numerator[i]/EO[[i]]} # NS/sqrt(n*n+1)
for (i in 1:length(numerator)) { EO[[i]]<-data.frame(EO[[i]],rep( DF$Stratum[i],length(
EO[[i]]))) }		#this convert into DF and put statum ID
EO<-do.call(rbind.data.frame, EO)
colnames(EO)<-c("PV","Stratum");
EO<-EO[order(-EO$PV),]
head(EO)
matx<-matrix(NA,nrow(EO),2)
matx[,1]<-EO$PV; matx[,2]<-EO$Stratum;
matx<- cbind(matx,matrix(0,nrow(EO),nrow(DFa) ),0,0)
colnames(matx) <- c("PV","Stratum", paste0("h_",DFa$Stratum), "n" , "Sd" )
######
matx <- rbind( matx[1,]*0, matx )
N <- DFa$N_h #nrow(matx)
matx[ 1 ,3:(ncol(matx) - 2)  ] <- DFa$MINn
matx[ 1 ,(ncol(matx) - 1) ] <- sum(matx[ 1 ,3:(ncol(matx) - 2)  ])
matx[ 1 ,(ncol(matx)) ] <- sqrt( sum((N*(N-matx[1,3:(ncol(matx)-2)])*
DFa$ss_err)/  (matx[1,3:(ncol(matx)-2)]) ) )
for (i in 2:10){
matx[i, 3:(2+nrow(DFa)) ] <- matx[i-1, 3:(2+nrow(DFa)) ]
matx[ i , which( colnames(matx) == paste0("h_", matx[i, 2] ) )] <-
matx[ i , which( colnames(matx) == paste0("h_", matx[i, 2] ) )] + 1
matx[i, (ncol(matx)-1)] <- sum(matx[i, 3:(ncol(matx)-2)] )
matx[i ,(ncol(matx)) ] <- sqrt( sum((N*(N-matx[i,3:
(ncol(matx)-2)])* DFa$ss_err)/  (matx[i,3:(ncol(matx)-2)]) ) )
}
matx[nrow(matx),3:(ncol(matx)-2)] <- DFa$N_h
matx[nrow(matx),  (ncol(matx)-1)] <- sum(matx[nrow(matx),3:(ncol(matx)-2)] )
matx[nrow(matx) ,(ncol(matx)) ] <- sqrt( sum((N*(N-matx[nrow(matx),3:
(ncol(matx)-2)])* DFa$ss_err)/  (matx[nrow(matx),3:(ncol(matx)-2)]) ) )
for( i in (nrow(matx)-1):(nrow(matx)-10) ){
matx[i,3:(ncol(matx)-2)] <-  matx[i+1,3:(ncol(matx)-2)]
matx[i, 2 +  matx[i+1 ,2]  ] <-  matx[i, 2 +  matx[i+1 ,2]  ] - 1
matx[i,  (ncol(matx)-1)] <- sum(matx[i,3:(ncol(matx)-2)] )
matx[i ,(ncol(matx)) ] <- sqrt( sum((N*(N-matx[i,3:
(ncol(matx)-2)])* DFa$ss_err)/  (matx[i,3:(ncol(matx)-2)]) ) )
}
#head(matx);tail(matx)
#sum(dat$CSR_PRVDD)
error <- sum(dat$CSR_PRVDD)*.0832 ;
#c( error - error *.1, error + error *.1 )
target <- error *.1 /  qnorm(.95)
for (i in 11:nrow(matx)){
if( matx[i-1, ncol(matx)] < target ){break}
matx[i, 3:(2+nrow(DFa)) ] <- matx[i-1, 3:(2+nrow(DFa)) ]
matx[ i , which( colnames(matx) == paste0("h_", matx[i, 2] ) )] <-
matx[ i , which( colnames(matx) == paste0("h_", matx[i, 2] ) )] + 1
matx[i, (ncol(matx)-1)] <- sum(matx[i, 3:(ncol(matx)-2)] )
}
##
print( as.data.frame( head(round(matx,2)) ) , row.names = F )
sum(dat$CSR_PRVDD)
TOTerror <- sum(dat$CSR_PRVDD)*.0832 ; TOTerror
TOTerror *.1; t1 <- TOTerror *.1
target <- TOTerror *.1 /  qnorm(.95); target
matx<-as.data.frame(matx)
DFa$s_err <- round(sqrt(as.numeric(DFa$ss_err)),2)
blergs <- sapply(stratum, function(X) sd(X$CSR_PRVDD ))
blergs[is.na(blergs)] <- 0
DFa$sdTA <- round(blergs,2)
#
DFa <- DFa[, c(1:5,ncol(DFa) , 6:(ncol(DFa)-1)) ]
DFa$n <-as.numeric( matx[ tail( which(matx$Sd >  target ) , 1 ) , 3:(ncol(matx)-2)] )
if( nrow( matx[ tail( which(matx$Sd >  target ) , 2 ) , 3:(ncol(matx)-0)] 	) == 0 ) { DFa$n <- DFa$MINn }
print(rbind(DFa,c("Totals", "-" , "-" , "", sum(as.numeric(DFa$TotAmnt)), sum(as.numeric(DFa$sdTA)), sum(DFa$N_h),
sum(DFa$MINn), sum(DFa$ss_err) , sum(DFa$s_err) ,sum(DFa$n)   )), row.names = F )
fy <- function(y,mu,ss,n)( prod( (1+ (1/(n-1) * ((y-mu)^2/(ss))))^(-n/2)  ) )
fx <- function(x){ ifelse( x < 0 , 0,
ifelse( 0 <= x & x < 0.5 ,  4*x ,
ifelse( 0.5 <= x & x <= 1, 4-4*x,
ifelse(  x < 1, 0, 0 )
)))}
### U(0,1) ###
curve(fx, from = 0-.05, to = 1+.05)
M <- 2
curve(M *dunif(x, 0, 1), add=TRUE, col="gold", lwd=2)
theta	<- vector(length = 1000)
arr <- NULL
t <- 1
count	<- 1
while(t < 100){
tb	<- runif(1)
U	<- runif(1)
r <- fx(tb) / (M*dunif(tb))
if(U < r){
theta[t] <- tb
t <- t + 1
points( tb , M*U , col = "red" , pch = 16) } else {
points( (tb) ,M*U , col = "blue" , pch = 4) }
count	<- count + 1 }
t/count
mean(theta)
### Beta(2,2) ###
curve(fx, from = 0-.05, to = 1+.05 )
M <- fx(.5) / ( (0.5)*(1-0.5) * (6) )
curve(M *dbeta(x, 2, 2), add=T, col="darkblue", lwd=2)
theta	<- vector(length = 1000)
arr <- NULL
t <- 1
count	<- 1
while(t < 100){
tb	<- rbeta(1,2,2)
U	<- runif(1)
r <- fx(tb) / (M*dbeta(tb,2,2))
if(U < r){
theta[t] <- tb
t <- t + 1
points( tb , M*U*dbeta(tb,2,2) , col = "red" , pch = 16) } else {
points( (tb) ,M*U*dbeta(tb,2,2) , col = "blue" , pch = 4) }
count	<- count + 1 }
t/count
#plot(density(theta), lwd = 8, col = 'blue')
#curve(dbeta(x, 6, 3), add = TRUE, col = 'red', lwd = 8)
mean(theta)
setwd("G:\\math\\640")
require(mvtnorm, quietly = T)
require(MCMCpack, quietly = T)
require(mcmcplots, quietly = T)
require(invgamma, quietly = T)
hers	<- read.table('hersreg.txt', header = TRUE)
colnames(hers)[1] <- "y"
hers0 <- hers[ which(hers[ ,2] == 0), 1:2]
B <- 10000
ss <- Alpha <- mu <- rep(NA,B)
ss[1] <- Alpha[1] <- mu[1] <- 1
v <- 1
n0 <- nrow(hers0)
set.seed(32717)
for (t in 2:B) {
Alpha[t] <- rinvgamma(1, (n0)/2 + .0001 ,
.0001 + (1/ss[t-1])  * sum( (hers0$y - mu[t-1] )^2 ) )
mu[t] <- rnorm(1, mean(hers0$y) , sqrt( Alpha[t]*ss[t-1] / n0) )
ss[t] <- rinvgamma( 1 , (n0/2)+.0001 ,  .0001 + (1/(2*Alpha[t])) *
sum( ( hers0$y - mu[t] )^2 )   )
}
# Burn in
Alpha <- matrix( tail(Alpha,B/2), ncol = 1);colnames(Alpha) <- "alpha"
mu <- matrix( tail(mu,B/2), ncol = 1);colnames(mu) <- "mu"
ss <- matrix( tail(ss,B/2), ncol = 1);colnames(ss) <- "sigma^2"
mcmcplot1(  ss , greek = T )
geweke.diag(mcmc(ss))
mcmcplot1(  Alpha, greek = T )
geweke.diag(mcmc(Alpha))
mcmcplot1(  mu , greek = T)
geweke.diag(mcmc(mu))
hers1 <- hers[ which(hers[ ,2] == 1), 1:2]
ss <- Alpha <- mu <- rep(NA,B)
ss[1] <- Alpha[1] <- mu[1] <- 1
v <- 1
n <- nrow(hers1)
set.seed(32717)
for (t in 2:B) {
Alpha[t] <- rinvgamma(1, (n)/2 + .1,
50 + (1/ 2 * ss[t-1])  * sum( (hers1$y - mu[t-1] )^2 ) )
mu[t] <- rnorm(1, mean(hers1$y) , sqrt( Alpha[t-1]*ss[t-1] / n) )
ss[t] <- rinvgamma( 1 , (n/2)+.1 ,  50 + (1/(2*Alpha[t])) *
sum( ( hers1$y - mu[t] )^2 )   )
}
# Burn in
Alpha <- matrix( tail(Alpha,B/2), ncol = 1);colnames(Alpha) <- "alpha"
mu <- matrix( tail(mu,B/2), ncol = 1);colnames(mu) <- "mu"
ss <- matrix( tail(ss,B/2), ncol = 1);colnames(ss) <- "sigma^2"
mcmcplot1(  ss , greek = T )
geweke.diag(mcmc(ss))
mcmcplot1(  Alpha, greek = T )
geweke.diag(mcmc(Alpha))
mcmcplot1(  mu , greek = T)
geweke.diag(mcmc(mu))
fy(  hers1$y, mean(hers1$y) , var(hers1$y), nrow(hers1) )
curve(fy(x, mean(hers1$y) , var(hers1$y), nrow(hers1) ), from = -100 , to = 100 )
fy <- function(y,mu,ss,n)(  ( (1+ (1/(n-1) * ((y-mu)^2/(ss))))^(-n/2)  ) )
fy(  hers1$y, mean(hers1$y) , var(hers1$y), nrow(hers1) )
curve(fy(x, mean(hers1$y) , var(hers1$y), nrow(hers1) ), from = -100 , to = 100 )
curve(dcauchy(x,median(hers1$y), sd(hers1$y)), from = -100 , to = 100 )
curve(fy(x, mean(hers1$y) , var(hers1$y), nrow(hers1) ), from = -100 , to = 100 , add = T )
setwd("G:\\math\\514")
source('hw5_514.R')
nnet1.fit
matrix( c(rnorm(10),rnorm(10),rnorm(10)), ncol = 3 )
Theta
c(x,y,xgrid,ygrid) %<-% data.lawrence.giles(12345)
setwd("G:\\math\\514")
source('hw5_514.R')
library(mlbench)
data=mlbench.spirals(75,1.5,.07)
plot(data)
X=t(data$x)
Y=matrix(as.integer(data$classes)-1,nrow=1)
c(x,y,xgrid,ygrid) %<-% data.lawrence.giles(12345)
np=length(x)
x.set=c(x)
y.set=c(y)
c(x,y,xgrid,ygrid) %<-% data.lawrence.giles(12345)
np=length(x)
x.set=c(x)
y.set=c(y)
degree=15
lm.fit = lm(y ~ poly(x,degree,raw=FALSE), data=data.frame(y=y.set,x=x.set))
yh = predict.lm(lm.fit,data.frame(x=xgrid))
plot(x.set, y.set, type='p', col='blue',
pch=19, ylim=c(-3,3), main='Linear Fit by N.Hid')
points(xgrid,yh,type="l",col="black",lwd=2)
legend("topright", legend = c(num_hidden,paste("degree=",degree)), col = colors,lwd=2 )
nnet1.fit
nnet1.fit
nnet1.fit
nnet1.fit.batch
nnet1.fit.batch
nnet1.fit.batch( x  , y , 1 , 3 ,  100 , 1500, 3,	Activation = sigmoid, Output = Sigmoid, 32 )
setwd("G:\\math\\514")
source('hw5_514.R')
library(mlbench)
data=mlbench.spirals(75,1.5,.07)
plot(data)
X=t(data$x)
Y=matrix(as.integer(data$classes)-1,nrow=1)
spirals <- spiralpred <- mlbench.spirals(75,1.5,.07)
y <- as.numeric(spirals$classes) - 1
spirals <- spiralpred <- mlbench.spirals(75,1.5,.07)
y <- as.numeric(spirals$classes) - 1
x <- t(spirals$x )
nnet1.fit.batch( x  , y , 1 , 3 ,  100 , 1500, 3,	Activation = sigmoid, Output = Sigmoid, 32 )
nnet1.fit.batch
nnet1.fit.batch
library(keras)
install.packages("Matrix")
library(keras)
nnet1.fit.batch
install_keras(tensorflow = "gpu",method = "conda")
install.packages('MCMCpack')
amazon
x_train
rm(list=ls())
library(keras)
library(tensorflow)
sess = tf$Session()
hello <- tf$constant('Hello, TensorFlow!')
sess$run(hello)
amdir <- "C:\\Users\\Administrator\\Documents\\reviews.csv"
amazon <- read.csv(  amdir , stringsAsFactors= F )
amazon$Text <- as.character(amazon$Text )
one.hot <- function(Z){return(unname( as.matrix(
as.data.frame( t( model.matrix(~ as.factor(Z) + 0) ) ) ) )) }
testsamples <- sample( 1:nrow(amazon)   , ((nrow(amazon) )/ 2 ))
trainsamples <-  setdiff(  1:nrow(amazon)   , testsamples)
ytrain <- amazon[trainsamples,]$Score
ytest <- amazon[testsamples ,]$Score
length(testsamples ) == length(trainsamples )
samples <- amazon[,10]; rm(amazon)
max_features <- 500
gc()
tokenizer <- text_tokenizer( num_words = max_features   ) %>%
fit_text_tokenizer(samples)
oh_results <- texts_to_matrix(tokenizer,samples, mode = "tfidf")
dim(oh_results)
x_train <- oh_results[trainsamples,]
x_test <- oh_results[testsamples ,]
rm(oh_results);gc()
ytrain <- t( one.hot(ytrain ) )
ytest <- t( one.hot(ytest) )
batch_size <- 32
embedding_dims <- 50
filters <- 250
kernel_size <- 3
hidden_dims <- 250
epochs <- 5
maxlen <- dim(x_train)[2]
model <- keras_model_sequential() %>%
#layer_embedding(input_dim=max_features,
#	 output_dim=embedding_dims, input_length = maxlen) %>%
#layer_dropout(rate=0.2) %>%
#layer_flatten(.) %>%
layer_dense(400 , activation = "relu", input_shape = maxlen )  %>%
layer_dropout(0.2) %>% regularizer_l1_l2(l1 = 0.01, l2 = 0.01) %>%
layer_dense(400 , activation = "relu"  )  %>%
layer_dropout(0.2) %>% regularizer_l1_l2(l1 = 0.01, l2 = 0.01) %>%
layer_dense(5 , activation = "softmax" )
model <- keras_model_sequential() %>%
layer_dense(400 , activation = "relu", input_shape = maxlen )  %>%
layer_dropout(0.2) %>%
layer_dense(400 , activation = "relu" )  %>%
layer_dropout(0.2) %>%
layer_dense(5 , activation = "softmax" )
gc()
# Compile model
model %>% compile(
loss = "categorical_crossentropy",
optimizer = "adagrad",
metrics = "accuracy"
)
# Training ----------------------------------------------------------------
model %>%
fit(
x_train, (ytrain),
batch_size = batch_size,
epochs = 20 ,
validation_data = list(x_test, (ytest ) )
)
## RNN's and embedding? What is pad sequences doing
# model %>% save_model_weights_hdf5("adagrad.h5")
model <- keras_model_sequential() %>%
layer_dense(400 , activation = "relu", input_shape = maxlen )  %>%
layer_dropout(0.2) %>%
layer_dense(400 , activation = "relu" )  %>%
layer_dropout(0.2) %>%
layer_dense(400 , activation = "relu" )  %>%
layer_dropout(0.2) %>%
layer_dense(5 , activation = "softmax" )
# Compile model
model %>% compile(
loss = "categorical_crossentropy",
optimizer = "adagrad",
metrics = "accuracy"
)
# Training ----------------------------------------------------------------
model %>%
fit(
x_train, (ytrain),
batch_size = batch_size,
epochs = 20 ,
validation_data = list(x_test, (ytest ) )
)
model
model %>% save_model_weights_hdf5("asdagrad.h5")
rm(list=ls())
gc()
setwd("G:\\math\\514")
library(keras)
library(tensorflow)
sess = tf$Session()
hello <- tf$constant('Hello, TensorFlow!')
sess$run(hello)
new_model <- load_model_hdf5( "adagrad.h5")
new_model %>% summary()
cat
cat('Test loss:', new_model, '\n')
cat('Test loss:', new_model$loss, '\n')
cat('Test accuracy:', new_model$acc, '\n')
new_model$acc
>
new_model %>% summary()
new_model %>% accuracy()
plot(new_model)
plot(new_model)
new_model %>% summary()
as.data.frame(new_model)
His <- new_model
as.data.frame(new_model)
as.data.frame(His)
plot(His)
names(new_model)
new_model$weights
new_model$metrics
new_model$metrics_names
new_model$cc
new_model$acc
new_model$metrics_updates
new_model$updates
new_model$summary
plot_model
new_model$fit
plot( new_model$fit )
new_model %>% metrics()
new_model %>% metrics()
new_model %>% metrics()
new_model %>% metrics
new_model$metrics
new_model$summary
new_model$losses
new_model$losses[[1]]
